---
title: "Threshold model inferred from data"
author: "Sebastian Schuster"
date: "4/4/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rwebppl)
library(ggplot2)
library(tidyr)
library(dplyr)
library(data.table)
library(gridExtra)


```

## Model

Literal listener (tries to infer the probability $\phi$ of getting a blue gumball given an utterance $u$):

$$P_L(\phi \mid u; \theta) \propto P(\phi) \left( {0.95} \times \mathbb{1}[\phi > \theta_{u}] + 0.05 * P_{uniform}(\phi; 0,1) \right)$$
(The term $0.05 * P_{uniform}(\phi; 0,1)$) corresponds to the noise term which assigns a small non-zero probability to all $\phi$ idependent of the actual utterance.) We assume that the prior $P(\phi)$ is uniform.


Pragmatic speaker (marginalizes over all possible values of $\theta$):

$$P_S(u \mid \phi, condition) \propto \int P(\theta) \exp\left(\lambda * \left(\log P_L(\phi \mid u; \theta) - c(u, condition)\right)\right) d\theta $$

Costs:

$$
c(u, condition) = 
     \begin{cases}
       0 &\quad\text{if } u  \text{ is one of the utterances in } condition\\
       c_{u} &\quad\text{otherwise} \\
     \end{cases}
$$

Prior over thresholds $\theta$:

$$P(\theta_u) = Beta(\alpha_u, \beta_u)$$


Estimated parameters:

$\alpha_u, \beta_u \sim Uniform(0,30)$, $c_u\sim Uniform(0,5)$, $\lambda \sim Uniform(.1,3)$


Left column: Experimental data.

Middle column: Model predictions with parameters estimated from all conditions.

Right column: Model predictions with parameters estimated from all conditions but the current one.

## Experimental data and model predictions

```{r load_data, echo=FALSE} 

load_data_for_plotting = function(fname) {


d = read.csv(fname)


d$modal1 = gsub('"', '', d$modal1)
d$modal2 = gsub('"', '', d$modal2)
d$pair = gsub('"', '', d$pair)
d$color = gsub('"', '', d$color)

modal1 = d$modal1[1]
modal2 = d$modal2[1]


drops <- c("modal1","rating1")
d2 = d[ , !(names(d) %in% drops)]
setnames(d2, old=c("rating2","modal2"), new=c("rating", "modal"))

drops <- c("modal2","rating2")
d3 = d[ , !(names(d) %in% drops)]
setnames(d3, old=c("rating1","modal1"), new=c("rating", "modal"))

drops <- c("modal2", "rating2", "modal1", "rating1")
d4 = d[ , !(names(d) %in% drops)]
d4$rating = d4$rating_other
d4$modal = "other"

d = rbind(d2, d3, d4)

d$modal = factor(d$modal, levels = c(modal1, modal2, "other"), ordered = TRUE)

d$percentage_blue_f = factor(d$percentage_blue)


d_blue = d %>% filter(., grepl("blue", sentence2))
d_orange = d %>% filter(., grepl("orange", sentence2))

#ggplot(d_orange, aes(x=percentage_blue, y=rating)) + geom_point(aes(col=modal)) +
# geom_smooth(aes(col=modal))

#ggplot(d_blue, aes(x=percentage_blue, y=rating)) + geom_point(aes(col=modal)) +  geom_smooth(aes(col=modal))

d_orange_reverse = d_orange
d_orange_reverse$percentage_blue = 100-d_orange$percentage_blue

d_comparison = rbind(d_blue, d_orange_reverse)
d_comparison$blue= grepl("blue", d_comparison$sentence2)
d_comparison$percentage_blue_f = factor(d_comparison$percentage_blue)

return(d_comparison)

}
  
load_data = function(fname) {
    d = read.csv(fname)
  
  d$modal1 = gsub('"', '', d$modal1)
  d$modal2 = gsub('"', '', d$modal2)
  d$pair = gsub('"', '', d$pair)
  d$color = gsub('"', '', d$color)

  
  d_blue = d %>% filter(., grepl("blue", sentence2))
  d_orange = d %>% filter(., grepl("orange", sentence2))
  
  #ggplot(d_orange, aes(x=percentage_blue, y=rating)) + geom_point(aes(col=modal)) +
  # geom_smooth(aes(col=modal))
  
  #ggplot(d_blue, aes(x=percentage_blue, y=rating)) + geom_point(aes(col=modal)) +    geom_smooth(aes(col=modal))
  
  d_orange_reverse = d_orange
  d_orange_reverse$percentage_blue = 100-d_orange$percentage_blue
  
  d_comparison = rbind(d_blue, d_orange_reverse)
  d_comparison$blue= grepl("blue", d_comparison$sentence2)
  
  return(d_comparison)
}

make_plots = function(d) {
  p1 = ggplot(d, aes(x=percentage_blue, y=rating)) + geom_point(aes(col=modal, alpha=.5)) +  geom_smooth(aes(col=modal), method="loess") + ggtitle(d$pair[1]) + xlab("percentage") +  theme(legend.position="none")

p2 = ggplot(d, aes(x=percentage_blue_f, y=rating, fill=modal)) + 
  geom_boxplot() +
  ggtitle(d$pair[1]) + xlab("percentage") +  theme(legend.position="none")


return(list("p1" = p1, "p2" = p2))
}


```






```{r model, echo=FALSE}

webppl_model = '


var limitedDiscreteUniform = cache(function(a,b) {
  return Infer({method: "enumerate"}, function(){
    var bins = _.range(a, b + 1 , 5);
    var probs = map(function(x){
        return 1 / bins.length;
      } , bins);
    return bins[discrete(probs)];
  });
});

var discreteUniform = limitedDiscreteUniform(0,100);

var discreteBeta = cache(function(params) {
  return Infer({method: "enumerate"}, function(){
    var bins = _.range(0, 1.01, .05);
    var probs = map(function(b){ Math.exp(Beta(params).score(b)) } , bins);
    var ret = bins[discrete(probs)];
    return ret;
  }
)});

var thetaParamDist = Infer({method: "enumerate"}, function(){
  var bins = _.range(0.1, 30.1 , 0.5);
  var probs = map(function(x){
      return 1 / bins.length;
    } , bins);
    var ret = bins[discrete(probs)];
  return ret;
});


var thetaParamPrior = function() {
  return sample(Uniform({a:0, b:30}));  
}

var costPrior = function() {
  return sample(Uniform({a:0, b:5})); 
}

var ratPrior = function() {
    return sample(Uniform({a:0.1, b:3})); 
}


var thetaPrior = function() {
    return sample(discreteUniform)
}


var probPrior = function() {
    return sample(discreteUniform)
}

  var utterances = ["bare", "might", "looks_like", "probably", "think", "could", "bare not"]



var utterancePrior = function() {
  return uniformDraw(utterances);
}

var literalListener = function(utterance, theta) {
  if (flip(0.05)) {
    return discreteUniform; //to account for noise
  } else if (utterance == "bare not") {
    return limitedDiscreteUniform(0, theta);
  } else {
    return limitedDiscreteUniform(theta, 100);
  }
};


var pragmaticSpeaker =  cache(function(prob, alphas, betas, costs, rat_alpha, modal1, modal2) {
  
  var theta_dists = {
    "bare": discreteBeta({a: alphas["bare"], b: betas["bare"]}),
    "might": discreteBeta({a: alphas["might"], b: betas["might"]}),
    "looks_like": discreteBeta({a: alphas["looks_like"], b: betas["looks_like"]}),
    "probably": discreteBeta({a: alphas["probably"], b: betas["probably"]}),
    "think": discreteBeta({a: alphas["think"], b: betas["think"]}),
    "could": discreteBeta({a: alphas["could"], b: betas["could"]}),
  }
  return Infer({model: function() {
    var utt = utterancePrior();
    var cost = (utt == modal1 || utt == modal2) ? 0 : costs[utt];
    var theta = utt == "bare not" ? 100 - Math.round(sample(theta_dists["bare"]) * 100) : Math.round(sample(theta_dists[utt]) * 100);
    factor(rat_alpha * (literalListener(utt, theta).score(prob) - cost) ); 
    return (utt == modal1 || utt == modal2) ? utt : "other";
  }, method:"enumerate"});
});

var model = function() {
return run();
}

var run = function() {
  var alphas = {
    "bare": data.params[0]["alpha_bare"],
    "might": data.params[0]["alpha_might"],
    "looks_like": data.params[0]["alpha_looks_like"],
    "probably": data.params[0]["alpha_probably"],
    "think": data.params[0]["alpha_think"],
    "could": data.params[0]["alpha_could"]
  };

  
  var betas = {
    "bare": data.params[0]["beta_bare"],
    "might":  data.params[0]["beta_might"],
    "looks_like": data.params[0]["beta_looks_like"],
    "probably": data.params[0]["beta_probably"],
    "think": data.params[0]["beta_think"],
    "could": data.params[0]["beta_could"]
  };

 

  var rat_alpha = data.params[0]["rat_alpha"];

  var costs = {
       "bare":  data.params[0]["cost_bare"],
       "might": data.params[0]["cost_might"],
       "looks_like": data.params[0]["cost_looks_like"],
       "probably": data.params[0]["cost_probably"],
       "think": data.params[0]["cost_think"],
       "could": data.params[0]["cost_could"],
       "bare not": data.params[0]["cost_bare_not"]
    };  


  var d = {
   modal1: data.modal1[0],
   modal2: data.modal2[0]
  }

  var xs = _.range(0,101, 5)
  var ys_modal1 = map(function(prob) { return Math.exp(pragmaticSpeaker(prob, alphas, betas, costs, rat_alpha, d.modal1, d.modal2).score(d.modal1))  }, xs);
  var ys_modal2 = map(function(prob) { return Math.exp(pragmaticSpeaker(prob, alphas, betas, costs, rat_alpha, d.modal1, d.modal2).score(d.modal2))  }, xs);
  var ys_other = map(function(prob) { return Math.exp(pragmaticSpeaker(prob, alphas, betas, costs, rat_alpha, d.modal1, d.modal2).score("other"))  }, xs);

  var res = map(function(idx) {
    return {x: xs[idx], y_modal1: ys_modal1[idx], y_modal2: ys_modal2[idx], y_other: ys_other[idx]};
  }, _.range(0, xs.length));


 return res;

}

'





```


```{r call, echo=FALSE}

  modals = c("bare", "might", "probably", "could", "looks_like", "think")


  model_params_all = read.csv(file = "./param-estimation-output-100k/params_all.csv")

  plot_posterior = function(modal1, modal2, exp_data, cond) {

       data_from_R = list(modal1=modal1, modal2=modal2, params=model_params_all[1,])

      post <- webppl(program_code = webppl_model, model_var = "model",
        inference_opts = list(method = "enumerate", verbose=TRUE), 
        data_var = "data", data = data_from_R)
      
      
      post = post[, !(names(post) %in% c("prob"))]
      colnames(post) <- c("percentage_blue", modal1, modal2, "other")
      
      post = (post %>% gather("modal", "rating_pred", -percentage_blue))
      
      post$modal = factor(post$modal, levels = c(modal1, modal2, "other"), ordered = TRUE)
      
      p = ggplot(post, aes(x=percentage_blue, y=rating_pred)) + geom_line(aes(col=modal)) +
          ggtitle(paste(modal1, modal2, sep="-")) + xlab("percentage") +  theme(legend.position="none")
      
      
      
      model_params_no_current_cond = read.csv(file = paste("./param-estimation-output-20k/params_no_cond_",cond , ".csv", sep=""))
      data_from_R = list(modal1=modal1, modal2=modal2, params=model_params_no_current_cond[1,])

      post2 <- webppl(program_code = webppl_model, model_var = "model",
        inference_opts = list(method = "enumerate", verbose=TRUE), 
        data_var = "data", data = data_from_R)
      
      
      post2 = post2[, !(names(post2) %in% c("prob"))]
      colnames(post2) <- c("percentage_blue", modal1, modal2, "other")
      
      post2 = (post2 %>% gather("modal", "rating_pred", -percentage_blue))
      
      post2$modal = factor(post2$modal, levels = c(modal1, modal2, "other"), ordered = TRUE)
      
      p2 = ggplot(post2, aes(x=percentage_blue, y=rating_pred)) + geom_line(aes(col=modal)) +
          ggtitle(paste(modal1, modal2, sep="-")) + xlab("percentage") +  theme(legend.position="none")
     
      
      
      exp_data = exp_data %>% 
        group_by(percentage_blue, modal) %>%
        summarise(rating_m = mean(rating))
      
      merged_data = merge(post, exp_data, by=c("percentage_blue", "modal"))
      merged_data2 = merge(post2, exp_data, by=c("percentage_blue", "modal"))

      
      model = lm(rating_pred ~ rating_m, data=merged_data)
      cat(paste("R^2:", summary(model)$r.squared), "\n")
            model = lm(rating_pred ~ rating_m, data=merged_data)

      model2 = lm(rating_pred ~ rating_m, data=merged_data2)
      cat(paste("R^2:", summary(model2)$r.squared))

      return(list(p1=p, p2=p2))

  }

  
  







```


```{r fig1, fig.width=10, echo=FALSE}

pairs = combn(modals, 2)
for (cond in seq(0,14)) {
  pair = pairs[,cond+1]
  fname = paste("../../experiments/0_pre_test/data/0_pre_test-cond", cond,"-trials.csv", sep="")
  p_data = load_data_for_plotting(fname)
  post_plot = plot_posterior(pair[1], pair[2], p_data, cond)
  data_plots = make_plots(p_data)
  
  grid.arrange(data_plots$p1, post_plot$p1, post_plot$p2, ncol=3)
  
}  

  fname = "../../experiments/0_pre_test/data/0_pre_test-cond5_2-trials.csv"
  p_data = load_data_for_plotting(fname)
  post_plot = plot_posterior("might", "probably", p_data, 5)
  data_plots = make_plots(p_data)
  
  grid.arrange(data_plots$p1, post_plot$p1, post_plot$p2, ncol=3)


```

## Threshold distributions

```{r fig2, fig.width=10, echo=FALSE, results='asis'}

ps = list()

for (modal in modals) {
  alpha_param_name = paste("alpha", modal, sep="_")
  beta_param_name = paste("beta", modal, sep="_")
  
  alpha_param = model_params_all[1,alpha_param_name]
  beta_param = model_params_all[1,beta_param_name]
  
  x = seq(0,1,.001)
  y = dbeta(x, alpha_param, beta_param)
  
  beta_density = data.frame(x = x, y = y)
  
  ps[[modal]] = ggplot(beta_density, aes(x=x, y=y)) + geom_line() + ggtitle(modal) + xlab("percentage")
}

grid.arrange(ps$bare, ps$might, ps$probably, ps$could, ps$think, ps$looks_like, ncol=3)


for (cond in seq(0,14)) {
  pair = pairs[,cond+1]
  model_params_no_current_cond = read.csv(file = paste("./param-estimation-output-20k/params_no_cond_",cond , ".csv", sep=""))

  for (modal in modals) {
    alpha_param_name = paste("alpha", modal, sep="_")
    beta_param_name = paste("beta", modal, sep="_")
    
    alpha_param = model_params_no_current_cond[1,alpha_param_name]
    beta_param = model_params_no_current_cond[1,beta_param_name]
    
    x = seq(0,1,.001)
    y = dbeta(x, alpha_param, beta_param)
    
    beta_density = data.frame(x = x, y = y)
    
    ps[[modal]] = ggplot(beta_density, aes(x=x, y=y)) + geom_line() + ggtitle(modal) + xlab("percentage")
  }
  
  cat(paste("<h3>", paste(pair[1], pair[2], sep="-"), "</h3>", sep=""))
  grid.arrange(ps$bare, ps$might, ps$probably, ps$could, ps$think, ps$looks_like, ncol=3)
}

```


